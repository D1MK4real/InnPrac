{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:25:53.556957825Z",
     "start_time": "2023-05-10T17:25:53.550650564Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pydiffvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:25:53.835252842Z",
     "start_time": "2023-05-10T17:25:53.821425449Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "import covergan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:25:54.054065065Z",
     "start_time": "2023-05-10T17:25:54.034046876Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = {'neutral': 0, 'happy': 1, 'sad': 2, 'surprise': 3, 'fear': 4, 'disgust': 5, 'anger': 6, 'contempt': 7}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:26:49.552843904Z",
     "start_time": "2023-05-10T17:26:49.529090745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<module 'covergan' from '/home/dmitriy/OVE/covergan/__init__.py'>"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib, sys\n",
    "importlib.reload(covergan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:26:50.635637888Z",
     "start_time": "2023-05-10T17:26:49.739260580Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('/home/dmitriy/OVE/official_data/artemis_dataset_release_v0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:26:50.640688957Z",
     "start_time": "2023-05-10T17:26:50.594677640Z"
    }
   },
   "outputs": [],
   "source": [
    "ndata = data[data['art_style']=='Color_Field_Painting'].groupby(['painting', 'art_style'])['emotion'].apply(lambda x: ','.join(x)).reset_index()\n",
    "ndata = ndata.drop([197,198,199]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:26:50.671310679Z",
     "start_time": "2023-05-10T17:26:50.597740573Z"
    }
   },
   "outputs": [],
   "source": [
    "# ndata = data[data['art_style']=='Color_Field_Painting'].groupby(['painting', 'art_style'])['emotion'].apply(lambda x: ','.join(x)).reset_index()\n",
    "# ndata = ndata.drop([197,198,199]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:26:50.671582566Z",
     "start_time": "2023-05-10T17:26:50.615866098Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "import covergan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:26:50.671801352Z",
     "start_time": "2023-05-10T17:26:50.618561983Z"
    }
   },
   "outputs": [],
   "source": [
    "# ndata.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:26:50.824628568Z",
     "start_time": "2023-05-10T17:26:50.807281326Z"
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "#\n",
    "# # Get the list of all files and directories\n",
    "# path = \"/home/dmitriy/OVE/data\"\n",
    "# dir_list = os.listdir(path)\n",
    "# dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:26:51.184226272Z",
     "start_time": "2023-05-10T17:26:51.168703411Z"
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "#\n",
    "# # Get the list of all files and directories\n",
    "# path = \"/home/dmitriy/OVE/data\"\n",
    "# dir_list = os.listdir(path)\n",
    "# dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:26:51.579421942Z",
     "start_time": "2023-05-10T17:26:51.550995167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{0: 'smiling',\n 1: 'sad',\n 2: 'surprise',\n 3: 'fear',\n 4: 'disgust',\n 5: 'anger',\n 6: 'contempt'}"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label= {'smiling': 0, 'sad': 1, 'surprise': 2, 'fear': 3, 'disgust': 4, 'anger': 5, 'contempt': 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:26:52.439545033Z",
     "start_time": "2023-05-10T17:26:52.425578661Z"
    }
   },
   "outputs": [],
   "source": [
    "# inputs = []\n",
    "# labels = []\n",
    "# for d1 in dir_list:\n",
    "#     dir_new = os.path.join(path,d1)\n",
    "#     images = os.listdir(dir_new)\n",
    "#     for image in images:\n",
    "#         inputs.append(image)\n",
    "#         labels.append(label[d1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:26:52.632285763Z",
     "start_time": "2023-05-10T17:26:52.609717161Z"
    }
   },
   "outputs": [],
   "source": [
    "# data = pd.DataFrame({\"image\":inputs,\"label\":labels})\n",
    "# data.to_csv('out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:26:52.826649317Z",
     "start_time": "2023-05-10T17:26:52.802938782Z"
    }
   },
   "outputs": [],
   "source": [
    "# data[data['image'].isin(data[data.duplicated('image')]['image'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:26:53.386060931Z",
     "start_time": "2023-05-10T17:26:53.371229302Z"
    }
   },
   "outputs": [],
   "source": [
    "# from colorer.music_palette_dataset import PaletteDatasetSmiles,ImageDatasetSmiles\n",
    "# dataset = PaletteDatasetSmiles(8,156,'name','/home/dmitriy/OVE/covergan/weights','/home/dmitriy/OVE/data1',pandas_dir='/home/dmitriy/OVE/out.csv')\n",
    "# dataset_image = ImageDatasetSmiles(8,156,'name','/home/dmitriy/OVE/covergan/weights','/home/dmitriy/OVE/data1',pandas_dir='/home/dmitriy/OVE/out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T17:23:52.030794982Z",
     "start_time": "2023-05-10T17:23:52.009086071Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset_image[0][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:23:54.073336418Z",
     "start_time": "2023-05-10T17:23:52.013486304Z"
    }
   },
   "outputs": [],
   "source": [
    "from colorer.music_palette_dataset import PaletteDataset,ImageDataset\n",
    "dataset = PaletteDataset(8,1599,'name','/home/dmitriy/OVE/covergan/weights','/home/dmitriy/OVE/wikiart',pandas_dir='/home/dmitriy/OVE/official_data/artemis_dataset_release_v0.csv')\n",
    "dataset_image = ImageDataset(8,1599,'name','/home/dmitriy/OVE/covergan/weights','/home/dmitriy/OVE/wikiart',pandas_dir='/home/dmitriy/OVE/official_data/artemis_dataset_release_v0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:23:54.092186818Z",
     "start_time": "2023-05-10T17:23:54.040461366Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.data = ndata\n",
    "dataset_image.data = ndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T17:23:54.092543578Z",
     "start_time": "2023-05-10T17:23:54.086884918Z"
    }
   },
   "outputs": [],
   "source": [
    "# for i in range(len(dataset_image)):\n",
    "#     print(dataset_image[i][1].shape)\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:29:25.721948394Z",
     "start_time": "2023-05-10T17:29:25.669635651Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:29:26.631119236Z",
     "start_time": "2023-05-10T17:29:26.608056911Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:34:26.690618115Z",
     "start_time": "2023-05-10T17:34:26.647913577Z"
    }
   },
   "outputs": [],
   "source": [
    "from colorer.models.colorer_dropout import Colorer2\n",
    "z_dim=32\n",
    "num_gen_layers=3\n",
    "colors_count = 8\n",
    "colorer = Colorer2(\n",
    "        z_dim=z_dim,\n",
    "        audio_embedding_dim=9,\n",
    "        num_layers=num_gen_layers,\n",
    "        colors_count=colors_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:36:35.486861328Z",
     "start_time": "2023-05-10T17:36:35.443348702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Colorer2(\n  (model_): Sequential(\n    (0): Linear(in_features=39, out_features=29, bias=True)\n    (1): Dropout(p=0.2, inplace=False)\n    (2): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): LeakyReLU(negative_slope=0.2)\n    (4): Linear(in_features=29, out_features=19, bias=True)\n    (5): Dropout(p=0.2, inplace=False)\n    (6): BatchNorm1d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): LeakyReLU(negative_slope=0.2)\n    (8): Linear(in_features=19, out_features=24, bias=True)\n    (9): Sigmoid()\n  )\n)"
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:36:35.738309931Z",
     "start_time": "2023-05-10T17:36:35.722388278Z"
    }
   },
   "outputs": [],
   "source": [
    "from colorer.models.gan_colorer import ColorerDiscriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:36:35.939871636Z",
     "start_time": "2023-05-10T17:36:35.923779309Z"
    }
   },
   "outputs": [],
   "source": [
    "disc = ColorerDiscriminator(audio_embedding_dim=9, num_layers=3,colors_count= colors_count).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:36:36.146288750Z",
     "start_time": "2023-05-10T17:36:36.117040891Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "ColorerDiscriminator(\n  (adv_layer): Sequential(\n    (0): Linear(in_features=31, out_features=21, bias=True)\n    (1): LeakyReLU(negative_slope=0.2)\n    (2): Dropout(p=0.2, inplace=False)\n    (3): Linear(in_features=21, out_features=11, bias=True)\n    (4): LeakyReLU(negative_slope=0.2)\n    (5): Dropout(p=0.2, inplace=False)\n    (6): Linear(in_features=11, out_features=8, bias=True)\n    (7): Sigmoid()\n  )\n)"
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:36:36.346209294Z",
     "start_time": "2023-05-10T17:36:36.330607652Z"
    }
   },
   "outputs": [],
   "source": [
    "def weighted_mse_loss(input, target, weight=None):\n",
    "    if weight is None:\n",
    "        max_weight = input.size()[1]\n",
    "        weight = torch.tensor([(max_weight - i // 3) // 3 for i in range(max_weight)]).to(input.device)\n",
    "        weight = weight.repeat((len(input), 1))\n",
    "    return (weight * (input - target) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:36:36.556723832Z",
     "start_time": "2023-05-10T17:36:36.541433547Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_noise(n_samples, input_dim, device):\n",
    "    \"\"\"\n",
    "    Function for creating noise vectors: Given the dimensions (n_samples, input_dim)\n",
    "    creates a tensor of that shape filled with random numbers from the normal distribution.\n",
    "    Parameters:\n",
    "        n_samples: the number of samples to generate, a scalar\n",
    "        input_dim: the dimension of the input vector, a scalar\n",
    "        device: the device type\n",
    "    \"\"\"\n",
    "    return torch.randn(n_samples, input_dim, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:36:36.771415774Z",
     "start_time": "2023-05-10T17:36:36.755474673Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "batch_size=64\n",
    "train_dataloader = DataLoader(dataset,drop_last=True, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:36:37.015820132Z",
     "start_time": "2023-05-10T17:36:36.957493470Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_checkpoint_filename(checkpoint_root: str, checkpoint_name: str, epoch: int = None) -> str:\n",
    "    suffix = f\"-{epoch}\" if epoch is not None else \"\"\n",
    "    return f\"{checkpoint_root}/{checkpoint_name}{suffix}.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:36:37.171178414Z",
     "start_time": "2023-05-10T17:36:37.155727388Z"
    }
   },
   "outputs": [],
   "source": [
    "from captioner_train import logger\n",
    "import os\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_root: str, checkpoint_name: str,\n",
    "                    models) -> int:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    filename = get_checkpoint_filename(checkpoint_root, checkpoint_name)\n",
    "\n",
    "    if os.path.isfile(filename):\n",
    "        logger.info(f\"Found {filename}, loading\")\n",
    "        checkpoint = torch.load(filename, map_location=device)\n",
    "        for i, model in enumerate(models):\n",
    "            model.load_state_dict(checkpoint[f\"{i}_state_dict\"])\n",
    "            print('Loaded')\n",
    "        epochs_done = checkpoint[f\"epochs_done\"]\n",
    "        logger.info(f\"{filename} loaded\")\n",
    "        return epochs_done\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:36:37.387846177Z",
     "start_time": "2023-05-10T17:36:37.359845146Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(checkpoint_root: str, checkpoint_name: str, epochs_done: int, backup_epochs: int,\n",
    "                    models):\n",
    "    checkpoint_dict = {}\n",
    "    for i, model in enumerate(models):\n",
    "        checkpoint_dict[f\"{i}_state_dict\"] = model.state_dict()\n",
    "    checkpoint_dict[f\"epochs_done\"] = epochs_done\n",
    "\n",
    "    if not backup_epochs:\n",
    "        # Unconditional save\n",
    "        filename = get_checkpoint_filename(checkpoint_root, checkpoint_name)\n",
    "        torch.save(checkpoint_dict, filename)\n",
    "        logger.info(f\"{filename} saved\")\n",
    "    if backup_epochs and epochs_done and epochs_done % backup_epochs == 0:\n",
    "        # Regular backup\n",
    "        filename = get_checkpoint_filename(checkpoint_root, checkpoint_name, epochs_done)\n",
    "        torch.save(checkpoint_dict, filename)\n",
    "        logger.info(f\"Backup {filename} saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:36:37.600205683Z",
     "start_time": "2023-05-10T17:36:37.567862239Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "ColorerDiscriminator(\n  (adv_layer): Sequential(\n    (0): Linear(in_features=31, out_features=21, bias=True)\n    (1): LeakyReLU(negative_slope=0.2)\n    (2): Dropout(p=0.2, inplace=False)\n    (3): Linear(in_features=21, out_features=11, bias=True)\n    (4): LeakyReLU(negative_slope=0.2)\n    (5): Dropout(p=0.2, inplace=False)\n    (6): Linear(in_features=11, out_features=8, bias=True)\n    (7): Sigmoid()\n  )\n)"
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:38:30.481026955Z",
     "start_time": "2023-05-10T17:36:39.012422758Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load checkpoint.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2500 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21d9a5100e264590b0f2bfd4c4e545bd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train LOSS: colorer 0.48655949036280316, disc 0.2731982469558716\n",
      "Train LOSS: colorer 0.4958668152491252, disc 0.20681717991828918\n",
      "Train LOSS: colorer 0.5060531298319498, disc 0.19580252468585968\n",
      "Train LOSS: colorer 0.5232499241828918, disc 0.1663130223751068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Backup /home/dmitriy/OVE/covergan/weights/smilef_colorer_8_colors_sorted-500.pt saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train LOSS: colorer 0.5440864761670431, disc 0.16918401420116425\n",
      "Train LOSS: colorer 0.5745754837989807, disc 0.15152589976787567\n",
      "Train LOSS: colorer 0.6131076614061991, disc 0.1335287094116211\n",
      "Train LOSS: colorer 0.6682819525400797, disc 0.1181754469871521\n",
      "Train LOSS: colorer 0.7587953408559164, disc 0.10908737033605576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Backup /home/dmitriy/OVE/covergan/weights/smilef_colorer_8_colors_sorted-1000.pt saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train LOSS: colorer 0.8545586268107096, disc 0.08639346808195114\n",
      "Train LOSS: colorer 1.0031739870707195, disc 0.07454031705856323\n",
      "Train LOSS: colorer 1.157206416130066, disc 0.0586550273001194\n",
      "Train LOSS: colorer 1.2762282689412434, disc 0.04763486236333847\n",
      "Train LOSS: colorer 1.4350755214691162, disc 0.03754989802837372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Backup /home/dmitriy/OVE/covergan/weights/smilef_colorer_8_colors_sorted-1500.pt saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train LOSS: colorer 1.6704594294230144, disc 0.036504268646240234\n",
      "Train LOSS: colorer 1.8246114253997803, disc 0.023918140679597855\n",
      "Train LOSS: colorer 2.0496483643849692, disc 0.02274121344089508\n",
      "Train LOSS: colorer 2.289135694503784, disc 0.04788561910390854\n",
      "Train LOSS: colorer 2.40719207127889, disc 0.012922600843012333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Backup /home/dmitriy/OVE/covergan/weights/smilef_colorer_8_colors_sorted-2000.pt saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train LOSS: colorer 2.5923765500386557, disc 0.008311358280479908\n",
      "Train LOSS: colorer 2.6242400805155435, disc 0.008156058378517628\n",
      "Train LOSS: colorer 2.8466714223225913, disc 0.00959360133856535\n",
      "Train LOSS: colorer 2.916548411051432, disc 0.007137061096727848\n",
      "Train LOSS: colorer 3.0522181193033853, disc 0.006072166841477156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Backup /home/dmitriy/OVE/covergan/weights/smilef_colorer_8_colors_sorted-2500.pt saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train LOSS: colorer 3.099476973215739, disc 0.005447130184620619\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import logging\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "n_epochs = 2500 # training_params[\"n_epochs\"]\n",
    "lr1 = 2e-4\n",
    "lr2 = 2e-4\n",
    "checkpoint_root ='/home/dmitriy/OVE/covergan/weights'\n",
    "backup_epochs = 100\n",
    "gen_opt = torch.optim.Adam(colorer.parameters(), lr=lr1)\n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=lr2)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "# model_name = f'colorer_{colorer.color_type}_{colorer.colors_count}_colors'\n",
    "model_name = f'smilef_colorer_{colorer.colors_count}_colors_{train_dataloader.dataset.sorted_color}'\n",
    "print(\"Trying to load checkpoint.\")\n",
    "epochs_done = load_checkpoint(checkpoint_root, model_name, [colorer, gen_opt])\n",
    "\n",
    "if epochs_done:\n",
    "    logger.info(f\"Loaded a checkpoint with {epochs_done} epochs done\")\n",
    "disc_repeats = 10\n",
    "step = 0\n",
    "log_interval = 100\n",
    "mean_iteration_disc_loss= 0\n",
    "cur_step = 0\n",
    "#\n",
    "for epoch in tqdm(range(epochs_done + 1, n_epochs + epochs_done + 1)):\n",
    "    colorer.train()\n",
    "    running_D_test_loss = 0.0\n",
    "    running_G_test_loss = 0.0\n",
    "    count = 0\n",
    "    count_disc = 0\n",
    "    for emotion, palette in train_dataloader:\n",
    "        palette = palette.to(device)\n",
    "\n",
    "        cur_batch_size = len(emotion)\n",
    "        emotion = emotion.float().to(device)\n",
    "        z = get_noise(cur_batch_size, z_dim, device=device)\n",
    "        fake_labels = torch.nn.functional.one_hot(torch.randint(0, 7, (cur_batch_size,)), 7)\n",
    "        # true_labels = torch.ones(batch_size).to(device).unsqueeze(-1)\n",
    "        if count%disc_repeats==0:\n",
    "            fake_covers = colorer(z, fake_labels)\n",
    "            disc_opt.zero_grad()\n",
    "            disc_real_pred = disc(palette, emotion)\n",
    "            real_disc_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred).to(device))\n",
    "            fake_disc_pred = disc(fake_covers.detach(), fake_labels)\n",
    "            gen_disc_loss = criterion(fake_disc_pred, torch.zeros_like(fake_disc_pred).to(device))\n",
    "            disc_loss = (real_disc_loss + gen_disc_loss) / 2\n",
    "            disc_loss.backward()\n",
    "            disc_opt.step()\n",
    "            mean_iteration_disc_loss = disc_loss.item()\n",
    "            running_D_test_loss += mean_iteration_disc_loss\n",
    "            count_disc+=1\n",
    "\n",
    "        disc_opt.zero_grad()\n",
    "        fake_covers =  colorer(z, fake_labels)\n",
    "        fake_disc_pred_gen = disc(fake_covers, fake_labels)\n",
    "        gen_loss = criterion(fake_disc_pred_gen, torch.ones_like(disc_real_pred).to(device))\n",
    "        gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "        running_G_test_loss += gen_loss.item()\n",
    "\n",
    "        count+=1\n",
    "        cur_step+=1\n",
    "\n",
    "    save_checkpoint(checkpoint_root, model_name, epoch, backup_epochs, [colorer, disc, gen_opt, disc_opt])\n",
    "    if (epoch + 1) % log_interval == 0:\n",
    "        avg_G_test_loss = running_G_test_loss / (count + 1)\n",
    "        avg_D_test_loss = running_D_test_loss / (count_disc+ 1)\n",
    "        print('Train LOSS: colorer {}, disc {}'.format(avg_G_test_loss, avg_D_test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T17:30:16.883497954Z",
     "start_time": "2023-05-10T17:30:16.864077225Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T17:30:17.231324185Z",
     "start_time": "2023-05-10T17:30:17.208999633Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:24:37.708520797Z",
     "start_time": "2023-05-10T17:24:37.612502349Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colorer.load_state_dict(torch.load('/home/dmitriy/OVE/covergan/weights/1smile_colorer_8_colors_sorted-500.pt')['0_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:33:52.028752125Z",
     "start_time": "2023-05-10T17:33:51.985104573Z"
    }
   },
   "outputs": [],
   "source": [
    "from outer.models.discriminator import Discriminator\n",
    "from outer.models.my_gen_fixed_6figs32_good import MyGeneratorFixedSixFigs32Good\n",
    "\n",
    "generator_type = MyGeneratorFixedSixFigs32Good\n",
    "discriminator_type = Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:38:35.976871749Z",
     "start_time": "2023-05-10T17:38:35.961261350Z"
    }
   },
   "outputs": [],
   "source": [
    "num_gen_layers = 4\n",
    "num_disc_conv_layers = 3\n",
    "num_disc_linear_layers = 2\n",
    "z_dim = 32 # Dimension of the noise vector\n",
    "# z_dim = 512  # Dimension of the noise vector\n",
    "\n",
    "# Painter properties\n",
    "path_count = 3\n",
    "path_segment_count = 4\n",
    "max_stroke_width = 0.01  # relative to the canvas size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:38:36.582588954Z",
     "start_time": "2023-05-10T17:38:36.463121550Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "MyGeneratorFixedSixFigs32Good(\n  (emb): Embedding(7, 7)\n  (model_): Sequential(\n    (0): Linear(in_features=39, out_features=256, bias=True)\n    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n    (3): Linear(in_features=256, out_features=512, bias=True)\n    (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n    (6): Linear(in_features=512, out_features=1024, bias=True)\n    (7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n    (9): Linear(in_features=1024, out_features=805, bias=True)\n    (10): Tanh()\n  )\n)"
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = MyGeneratorFixedSixFigs32Good(z_dim,9,num_gen_layers,128,max_stroke_width)\n",
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:38:36.724180360Z",
     "start_time": "2023-05-10T17:38:36.559790826Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Discriminator(\n  (emb): Embedding(7, 7)\n  (model): Sequential(\n    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (1): LeakyReLU(negative_slope=0.2)\n    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (4): LeakyReLU(negative_slope=0.2)\n    (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): Conv2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (8): AdaptiveAvgPool2d(output_size=1)\n    (9): Sigmoid()\n  )\n  (adv_layer): Sequential(\n    (0): Linear(in_features=39, out_features=1, bias=True)\n    (1): Sigmoid()\n  )\n)"
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc = Discriminator(128,9,3,2)\n",
    "disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:38:36.726529449Z",
     "start_time": "2023-05-10T17:38:36.569418566Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0., 1., 0., 0., 0., 0., 0.])"
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "dataset_image[6][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:38:36.899731421Z",
     "start_time": "2023-05-10T17:38:36.679124052Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_losses(epoch: int, cur_step: int, display_steps: int, bin_steps: int, losses: [(str, [float])]):\n",
    "    if cur_step % display_steps == 0 and cur_step > 0:\n",
    "        loss_stats = []\n",
    "\n",
    "        for loss_name, loss_values in losses:\n",
    "            loss_mean = sum(loss_values[-display_steps:]) / display_steps\n",
    "            if \"loss\" not in loss_name.lower() and \"metric\" not in loss_name.lower():\n",
    "                loss_name += \" Loss\"\n",
    "            loss_stats.append(f\"{loss_name}: {loss_mean}\")\n",
    "\n",
    "            num_examples = (len(loss_values) // bin_steps) * bin_steps\n",
    "            plt.plot(\n",
    "                range(num_examples // bin_steps),\n",
    "                torch.Tensor(loss_values[:num_examples]).view(-1, bin_steps).mean(1),\n",
    "                label=loss_name\n",
    "            )\n",
    "\n",
    "        logger.info(f\"Epoch {epoch} (step {cur_step}): \" + \", \".join(loss_stats))\n",
    "        plt.legend()\n",
    "        print(\"Saving losses to png file\")\n",
    "        import covergan_train\n",
    "        # plt.savefig(f\"{covergan_train.logger.plots_dir}/losses-{epoch}-{cur_step}.png\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    elif cur_step == 0:\n",
    "        logger.info(\"The training is working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:38:37.073443642Z",
     "start_time": "2023-05-10T17:38:36.686453736Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:38:37.145944566Z",
     "start_time": "2023-05-10T17:38:36.709938845Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_gradient_penalty(disc, real, fake, audio_embedding):\n",
    "    # Mix the images together\n",
    "    epsilon = torch.rand((real.size(0), 1, 1, 1), device=real.device)\n",
    "    mixed_images = (real * epsilon + fake * (1 - epsilon)).requires_grad_(True)\n",
    "\n",
    "    # Calculate the critic's scores on the mixed images\n",
    "    mixed_scores = disc(mixed_images, audio_embedding)\n",
    "\n",
    "    # Take the gradient of the scores with respect to the images\n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=mixed_images,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    gradient = gradient.view(len(gradient), -1)\n",
    "\n",
    "    # Calculate the magnitude of every row\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "\n",
    "    # Penalize the mean squared distance of the gradient norms from 1\n",
    "    penalty = ((gradient_norm - 1) ** 2).mean()\n",
    "    return penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:38:37.150254780Z",
     "start_time": "2023-05-10T17:38:36.839526753Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_grad_flow(named_parameters, model_name: str, epoch=None, cur_step=None):\n",
    "    \"\"\"Plots the gradients flowing through different layers in the network during training.\n",
    "    Can be used for checking for possible gradient vanishing/exploding problems.\n",
    "\n",
    "    Usage: Plug this function in Trainer class after loss.backwards() as\n",
    "    `plot_grad_flow(self.model.named_parameters())` to visualize the gradient flow\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the stats\n",
    "    avg_grads = []\n",
    "    max_grads = []\n",
    "    layers = []\n",
    "    for n, p in named_parameters:\n",
    "        if p.requires_grad and (\"bias\" not in n) and p.grad is not None:\n",
    "            layers.append(n)\n",
    "            avg_grads.append(p.grad.abs().mean())\n",
    "            max_grads.append(p.grad.abs().max())\n",
    "\n",
    "    # Initialize plot canvas\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(6, 6)\n",
    "\n",
    "    # Plot\n",
    "    plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.2, lw=1, color=\"c\")  # Max gradients\n",
    "    plt.bar(np.arange(len(max_grads)), avg_grads, alpha=0.2, lw=1, color=\"b\")  # Mean gradients\n",
    "    plt.hlines(0, 0, len(avg_grads) + 1, lw=2, color=\"k\")  # Zero gradient line\n",
    "    plt.xticks(range(0, len(avg_grads), 1), layers, rotation=\"vertical\")\n",
    "\n",
    "    # Set display options\n",
    "    plt.xlim(left=0, right=len(avg_grads))\n",
    "    plt.ylim(bottom=-0.001, top=0.02)  # Zoom in on the lower gradient regions\n",
    "    plt.xlabel('Layers')\n",
    "    plt.ylabel('average gradient')\n",
    "    plt.title(f'Gradient flow in {model_name}')\n",
    "    plt.grid(True)\n",
    "    plt.legend(\n",
    "        [\n",
    "            Line2D([0], [0], color=\"c\", lw=4),\n",
    "            Line2D([0], [0], color=\"b\", lw=4),\n",
    "            Line2D([0], [0], color=\"k\", lw=4)\n",
    "        ],\n",
    "        [\n",
    "            'max-gradient',\n",
    "            'mean-gradient',\n",
    "            'zero-gradient'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.plot()\n",
    "    if epoch is not None:\n",
    "        print(\"Saving grad flow to png file\")\n",
    "        import covergan_train\n",
    "        # plt.savefig(f\"{covergan_train.logger.plots_dir}/grad-flow-{epoch}-{cur_step}.png\")\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:38:37.209932124Z",
     "start_time": "2023-05-10T17:38:36.849285450Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_real_fake_covers(emotions,real_cover_tensor: torch.Tensor, fake_cover_tensor: torch.Tensor,\n",
    "                          disc_real_pred: torch.Tensor = None, disc_fake_pred: torch.Tensor = None,\n",
    "                          epoch=None, cur_step=None, plot_saving_dir=\"./plots\"):\n",
    "    sample_count = 5  # max covers to draw\n",
    "\n",
    "    real_cover_tensor = real_cover_tensor[:sample_count]\n",
    "    fake_cover_tensor = fake_cover_tensor[:sample_count]\n",
    "    emotions = emotions[:sample_count].numpy()\n",
    "\n",
    "    rows = min(sample_count, len(real_cover_tensor))\n",
    "    cols = 2\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(6 * cols, 6 * rows)\n",
    "    for i in range(rows):\n",
    "        real = real_cover_tensor[i]\n",
    "        fake = fake_cover_tensor[i]\n",
    "        emotion = emotions[i]\n",
    "        emo = []\n",
    "        for j in range(len(emotion)):\n",
    "            if emotion[j]==1:\n",
    "                emo.append(key_val[j])\n",
    "        # real_pil = to_pil_image(real,mode=\"RGB\")\n",
    "        fake_pil = to_pil_image(fake,mode=\"RGB\")\n",
    "\n",
    "        real_score = disc_real_pred[i].item() if disc_real_pred is not None else None\n",
    "        fake_score = disc_fake_pred[i].item() if disc_fake_pred is not None else None\n",
    "\n",
    "        for (j, (pil, score)) in enumerate([((real/255).permute(1,2,0), real_score), (fake_pil, fake_score)]):\n",
    "            plt.subplot(rows, cols, i * cols + j + 1)\n",
    "            plt.imshow(pil)\n",
    "            if score is not None:\n",
    "                plt.text(10, 10, f'{emo}', backgroundcolor='w', fontsize=10.0)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.plot()\n",
    "    if epoch is not None:\n",
    "        print(\"Saving covers to png file\")\n",
    "        import covergan_train\n",
    "        # print(covergan_train.logger.plots_dir)\n",
    "        # plt.savefig(f\"{covergan_train.logger.plots_dir}/covers-{epoch}-{cur_step}.png\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:38:37.215919996Z",
     "start_time": "2023-05-10T17:38:36.856438845Z"
    }
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset_image,drop_last=True, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:38:37.219772440Z",
     "start_time": "2023-05-10T17:38:36.875260261Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def mismatching_permute(t: torch.Tensor) -> torch.Tensor:\n",
    "    shift = random.randrange(start=0, stop=len(t))\n",
    "    return torch.cat((t[shift:], t[:shift]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "palette_generator = colorer\n",
    "def generate(z, audio_embedding_disc):\n",
    "    if palette_generator is None:\n",
    "        return gen(z, audio_embedding_disc)\n",
    "    return gen(z, audio_embedding_disc, palette_generator=palette_generator)\n",
    "\n",
    "logger.info(f'PyDiffVG uses GPU: {pydiffvg.get_use_gpu()}')\n",
    "# logger.info(gen)\n",
    "# logger.info(disc)\n",
    "\n",
    "n_epochs = 1000\n",
    "disc_repeats = 5#Discriminator runs per iteration\n",
    "\n",
    "\n",
    "disc_lr = gen_lr = 0.0003\n",
    "\n",
    "z_dim = 32\n",
    "disc_slices = 1\n",
    "checkpoint_root = '/home/dmitriy/OVE/covergan/weights'\n",
    "display_steps = 5\n",
    "backup_epochs = 5\n",
    "bin_steps = 20\n",
    "plot_grad = False\n",
    "c_lambda = 10\n",
    "new_loss = torch.nn.BCELoss()\n",
    "new_loss_log = torch.nn.BCEWithLogitsLoss()\n",
    "batch_size=8\n",
    "dataloader = DataLoader(dataset_image,drop_last=True, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=gen_lr)\n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=disc_lr)\n",
    "cgan_out_name='cgan_out'\n",
    "print(\"Trying to load checkpoint.\")\n",
    "epochs_done = load_checkpoint(checkpoint_root, cgan_out_name, [gen, disc, gen_opt, disc_opt])\n",
    "if epochs_done:\n",
    "    logger.info(f\"Loaded a checkpoint with {epochs_done} epochs done\")\n",
    "\n",
    "cur_step = 0\n",
    "generator_losses = []\n",
    "discriminator_losses = []\n",
    "shuffle_losses = []\n",
    "val_metrics = []\n",
    "\n",
    "disc_repeat_cnt = 0\n",
    "mean_iteration_disc_loss, mean_shuffle_disc_loss = 0, 0\n",
    "for epoch in range(epochs_done + 1, n_epochs + epochs_done + 1):\n",
    "    for emotion, image in tqdm(dataloader):\n",
    "        torch.cuda.empty_cache()\n",
    "        emotion = emotion.float().to(device)\n",
    "        image = image.to(device)\n",
    "        cur_batch_size = len(emotion)\n",
    "\n",
    "        z = get_noise(cur_batch_size, z_dim, device=device)\n",
    "\n",
    "        fake_labels = torch.nn.functional.one_hot(torch.randint(0, 7, (cur_batch_size,)), 7).to(device)\n",
    "\n",
    "        true_labels = torch.ones(batch_size).to(device).unsqueeze(-1)\n",
    "\n",
    "        if cur_step%disc_repeats==0:\n",
    "          fake_covers = generate(z, fake_labels)\n",
    "          disc_opt.zero_grad()\n",
    "          disc_real_pred = disc(image.permute(0, 3, 1, 2), emotion)\n",
    "\n",
    "\n",
    "          real_disc_loss = new_loss(disc_real_pred, true_labels)\n",
    "\n",
    "          fake_disc_pred = disc(fake_covers.detach(), fake_labels)\n",
    "\n",
    "          gen_disc_loss = new_loss(fake_disc_pred, torch.zeros(batch_size).unsqueeze(-1).to(device))\n",
    "\n",
    "          disc_loss = (real_disc_loss + gen_disc_loss) / 2\n",
    "          # disc_loss.backward()\n",
    "          disc_opt.step()\n",
    "          mean_iteration_disc_loss = disc_loss.item()\n",
    "          if cur_step % display_steps == 0:\n",
    "            plot_losses(epoch, cur_step, display_steps, bin_steps, [\n",
    "                (\"Generator\", generator_losses),\n",
    "                (\"Discriminator Adversarial\", discriminator_losses),\n",
    "                (\"Discriminator Mismatches\", shuffle_losses)\n",
    "            ])\n",
    "\n",
    "            plot_real_fake_covers(fake_labels, image.permute(0, 3, 1, 2), fake_covers, disc_real_pred, fake_disc_pred, epoch=epoch,\n",
    "                                    cur_step=cur_step)\n",
    "            # save_checkpoint(checkpoint_root, cgan_out_name, epoch, 0, [gen, disc, gen_opt, disc_opt])\n",
    "\n",
    "        discriminator_losses.append(mean_iteration_disc_loss)\n",
    "\n",
    "        gen_opt.zero_grad()\n",
    "        fake_covers = generate(z, fake_labels)\n",
    "\n",
    "        fake_disc_pred_gen = disc(fake_covers, fake_labels)\n",
    "        gen_loss = new_loss(fake_disc_pred_gen, true_labels)\n",
    "\n",
    "        # gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "\n",
    "        generator_losses.append(gen_loss.item())\n",
    "\n",
    "        # if cur_step % display_steps == 0:\n",
    "        #     plot_losses(epoch, cur_step, display_steps, bin_steps, [\n",
    "        #         (\"Generator\", generator_losses),\n",
    "        #         (\"Discriminator Adversarial\", discriminator_losses),\n",
    "        #         (\"Discriminator Mismatches\", shuffle_losses)\n",
    "        #     ])\n",
    "\n",
    "        #     plot_real_fake_covers(fake_labels, image.permute(0, 3, 1, 2), fake_covers, disc_real_pred, fake_disc_pred, epoch=epoch,\n",
    "        #                             cur_step=cur_step)\n",
    "        #     save_checkpoint(checkpoint_root, cgan_out_name, epoch, 0, [gen, disc, gen_opt, disc_opt])\n",
    "        \n",
    "        cur_step += 1\n",
    "\n",
    "\n",
    "        # ### Update discriminator with fakes ###\n",
    "        # Zero out the discriminator gradients\n",
    "\n",
    "        # if disc_repeat_cnt == disc_repeats:\n",
    "\n",
    "        # Make sure that enough predictions were made\n",
    "        # Shapes must match\n",
    "\n",
    "        # gp = get_gradient_penalty(disc, image.permute(0,3,1,2).data, fake_cover_tensor.data,\n",
    "        #                           emotion)\n",
    "\n",
    "                    # + c_lambda*gp\n",
    "        # disc_loss = disc_fake_pred.mean() - disc_real_pred.mean() + c_lambda*gp\n",
    "        # Keep track of the average critic loss in this batch\n",
    "        # Update gradients\n",
    "        # disc_loss.backward()\n",
    "        # if plot_grad:\n",
    "        #     plot_grad_flow(disc.named_parameters(), \"discriminator (fakes)\", epoch=epoch, cur_step=cur_step)\n",
    "        # Update optimizer\n",
    "        \n",
    "        \n",
    "        \n",
    "        ###\n",
    "        # shuffle_cover_tensor = mismatching_permute(image.permute(0,3,1,2))###\n",
    "        #\n",
    "        # if True:\n",
    "        #     # ### Update discriminator with matching and shuffled cover-embedding pairs ###\n",
    "        #     disc_opt.zero_grad()\n",
    "        #\n",
    "        #     disc_real_pred = disc(image.permute(0,3,1,2), emotion)\n",
    "        #     disc_shuffle_pred = disc(shuffle_cover_tensor, emotion)\n",
    "        #     # disc_loss = disc_shuffle_pred.mean() - disc_real_pred.mean()\n",
    "        #     disc_loss = new_loss(disc_shuffle_pred,torch.zeros_like(disc_shuffle_pred))+new_loss(disc_real_pred,torch.ones_like(disc_real_pred))\n",
    "        #     mean_shuffle_disc_loss += disc_loss.item() / disc_repeats\n",
    "        #\n",
    "        #     # Update gradients\n",
    "        #     # disc_loss.backward()\n",
    "        #     if plot_grad:\n",
    "        #         plot_grad_flow(disc.named_parameters(), \"discriminator (shuffled pairs)\", epoch=epoch,\n",
    "        #                        cur_step=cur_step)\n",
    "        #     disc_opt.step()\n",
    "\n",
    "            # Keep track of the average discriminator loss\n",
    "        # discriminator_losses.append(mean_iteration_disc_loss)\n",
    "        # shuffle_losses.append(mean_shuffle_disc_loss)\n",
    "        # disc_repeat_cnt += 1\n",
    "        # mean_iteration_disc_loss, mean_shuffle_disc_loss = 0, 0\n",
    "\n",
    "        # ### Update generator ###\n",
    "        # Zero out the generator gradients\n",
    "        # gen_opt.zero_grad()\n",
    "\n",
    "        # # Getting fake shapes, same as in the loop above\n",
    "        # fake_cover_tensor, disc_fake_pred, fig_params = get_fake_pred(should_detach=False)\n",
    "\n",
    "        # p_dist = torch.nn.PairwiseDistance()\n",
    "        # dist_loss_sum = torch.tensor(0.0).to(fake_cover_tensor.device)\n",
    "        # for figs in fig_params:\n",
    "        #     cur_batch_dist_loss = torch.tensor(0.0).to(fake_cover_tensor.device)\n",
    "        #     for ind_x, x in enumerate(figs):\n",
    "        #         for ind_y in range(ind_x + 1, len(figs)):\n",
    "        #             a = x[\"center_point\"]\n",
    "        #             b = figs[ind_y][\"center_point\"]\n",
    "        #             cur_batch_dist_loss += 50000 / (p_dist(a, b)) ** 3\n",
    "        #     dist_loss_sum += cur_batch_dist_loss / len(figs)\n",
    "        #\n",
    "        # dist_loss_sum = dist_loss_sum / len(fig_params)\n",
    "        # dist_loss_sum.backward()\n",
    "        # gen_loss = -disc_fake_pred.mean() + dist_loss_sum\n",
    "        # gen_loss = -disc_fake_pred.mean()\n",
    "\n",
    "        # gen_loss = new_loss(disc_fake_pred,torch.ones_like(disc_fake_pred))\n",
    "        # # gen_loss.backward()\n",
    "        # # gen_loss.backward()\n",
    "        # if plot_grad:\n",
    "        #     plot_grad_flow(gen.named_parameters(), \"generator\", epoch=epoch, cur_step=cur_step)\n",
    "\n",
    "        # Update the weights\n",
    "        # gen_opt.step()\n",
    "\n",
    "        # # Keep track of the generator losses\n",
    "        # generator_losses.append(gen_loss.item())\n",
    "        # # clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = get_noise(2, z_dim, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader2 = DataLoader(dataset_image,drop_last=True, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(dataloader2))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = gen(z, a, palette_generator=palette_generator,return_diffvg_svg_params=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, params in enumerate(b):\n",
    "    pydiffvg.save_svg(f'/home/dmitriy/OVE/plots/back_diffvg_svg_{ind}.svg', *params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from service_utils import add_filter\n",
    "# from service_utils import OverlayFilter\n",
    "# num_samples = 2\n",
    "# # filtered_samples = round(num_samples // 2)\n",
    "# filtered_samples = num_samples\n",
    "# filters = list(OverlayFilter)\n",
    "# for psvg_cover in b[-filtered_samples:]:\n",
    "#     overlay_filter = random.choice(filters)\n",
    "#     add_filter(psvg_cover, overlay_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
