{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:39:05.627334761Z",
     "start_time": "2023-05-04T23:39:05.583647381Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pydiffvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:39:06.363877957Z",
     "start_time": "2023-05-04T23:39:06.307635466Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "import covergan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:39:06.708938720Z",
     "start_time": "2023-05-04T23:39:06.317615255Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = {'neutral': 0, 'happy': 1, 'sad': 2, 'surprise': 3, 'fear': 4, 'disgust': 5, 'anger': 6, 'contempt': 7}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:39:06.772025728Z",
     "start_time": "2023-05-04T23:39:06.610410148Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<module 'covergan' from '/home/dmitriy/OVE/covergan/__init__.py'>"
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib, sys\n",
    "importlib.reload(covergan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:39:07.983267382Z",
     "start_time": "2023-05-04T23:39:06.617347882Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('/home/dmitriy/OVE/official_data/artemis_dataset_release_v0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:39:07.983827029Z",
     "start_time": "2023-05-04T23:39:07.973954073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{0: 'something else',\n 1: 'sadness',\n 2: 'contentment',\n 3: 'awe',\n 4: 'amusement',\n 5: 'excitement',\n 6: 'fear',\n 7: 'disgust',\n 8: 'anger'}"
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_key = dict(zip(data.emotion.unique(), data.index))\n",
    "key_val = {v:k for k,v in val_key.items()}\n",
    "key_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:39:07.986055692Z",
     "start_time": "2023-05-04T23:39:07.974187519Z"
    }
   },
   "outputs": [],
   "source": [
    "ndata = data[data['art_style']=='Color_Field_Painting'].groupby(['painting', 'art_style'])['emotion'].apply(lambda x: ','.join(x)).reset_index()\n",
    "ndata = ndata.drop([197,198,199]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:39:07.986132721Z",
     "start_time": "2023-05-04T23:39:07.974314411Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "import covergan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:39:07.986192537Z",
     "start_time": "2023-05-04T23:39:07.974354732Z"
    }
   },
   "outputs": [],
   "source": [
    "# ndata.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:39:07.986483959Z",
     "start_time": "2023-05-04T23:39:07.977998453Z"
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "#\n",
    "# # Get the list of all files and directories\n",
    "# path = \"/home/dmitriy/OVE/data\"\n",
    "# dir_list = os.listdir(path)\n",
    "# dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:39:08.325917490Z",
     "start_time": "2023-05-04T23:39:08.242561883Z"
    }
   },
   "outputs": [],
   "source": [
    "# label= {'smiling': 0, 'sad': 1, 'surprise': 2, 'fear': 3, 'disgust': 4, 'anger': 5, 'contempt': 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:39:08.591895521Z",
     "start_time": "2023-05-04T23:39:08.275551735Z"
    }
   },
   "outputs": [],
   "source": [
    "# key_val = {v:k for k,v in label.items()}\n",
    "# key_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:39:08.887148295Z",
     "start_time": "2023-05-04T23:39:08.574177404Z"
    }
   },
   "outputs": [],
   "source": [
    "# inputs = []\n",
    "# labels = []\n",
    "# for d1 in dir_list:\n",
    "#     dir_new = os.path.join(path,d1)\n",
    "#     images = os.listdir(dir_new)\n",
    "#     for image in images:\n",
    "#         inputs.append(image)\n",
    "#         labels.append(label[d1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:39:09.173602545Z",
     "start_time": "2023-05-04T23:39:08.866979637Z"
    }
   },
   "outputs": [],
   "source": [
    "# data = pd.DataFrame({\"image\":inputs,\"label\":labels})\n",
    "# data.to_csv('out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:39:09.216060542Z",
     "start_time": "2023-05-04T23:39:09.153523095Z"
    }
   },
   "outputs": [],
   "source": [
    "# data[data['image'].isin(data[data.duplicated('image')]['image'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:39:09.846651774Z",
     "start_time": "2023-05-04T23:39:09.559338764Z"
    }
   },
   "outputs": [],
   "source": [
    "# from colorer.music_palette_dataset import PaletteDatasetSmiles,ImageDatasetSmiles\n",
    "# dataset = PaletteDatasetSmiles(8,156,'name','/home/dmitriy/OVE/covergan/weights','/home/dmitriy/OVE/data1',pandas_dir='/home/dmitriy/OVE/out.csv')\n",
    "# dataset_image = ImageDatasetSmiles(8,156,'name','/home/dmitriy/OVE/covergan/weights','/home/dmitriy/OVE/data1',pandas_dir='/home/dmitriy/OVE/out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T23:39:10.133062160Z",
     "start_time": "2023-05-04T23:39:09.838224516Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset_image[0][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:39:12.474625525Z",
     "start_time": "2023-05-04T23:39:10.635775881Z"
    }
   },
   "outputs": [],
   "source": [
    "from colorer.music_palette_dataset import PaletteDataset,ImageDataset\n",
    "dataset = PaletteDataset(8,1599,'name','/home/dmitriy/OVE/covergan/weights','/home/dmitriy/OVE/wikiart',pandas_dir='/home/dmitriy/OVE/official_data/artemis_dataset_release_v0.csv')\n",
    "dataset_image = ImageDataset(8,1599,'name','/home/dmitriy/OVE/covergan/weights','/home/dmitriy/OVE/wikiart',pandas_dir='/home/dmitriy/OVE/official_data/artemis_dataset_release_v0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:39:12.474832458Z",
     "start_time": "2023-05-04T23:39:12.422887911Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.data = ndata\n",
    "dataset_image.data = ndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T23:39:12.474912099Z",
     "start_time": "2023-05-04T23:39:12.423142454Z"
    }
   },
   "outputs": [],
   "source": [
    "# for i in range(len(dataset_image)):\n",
    "#     print(dataset_image[i][1].shape)\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:39:12.474951601Z",
     "start_time": "2023-05-04T23:39:12.423192257Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:39:12.477399401Z",
     "start_time": "2023-05-04T23:39:12.426492740Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:39:12.551305880Z",
     "start_time": "2023-05-04T23:39:12.469424258Z"
    }
   },
   "outputs": [],
   "source": [
    "from colorer.models.colorer_dropout import Colorer2\n",
    "z_dim=32\n",
    "num_gen_layers=3\n",
    "colors_count = 8\n",
    "colorer = Colorer2(\n",
    "        z_dim=z_dim,\n",
    "        audio_embedding_dim=9,\n",
    "        num_layers=num_gen_layers,\n",
    "        colors_count=colors_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:39:13.406782277Z",
     "start_time": "2023-05-04T23:39:13.354142431Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Colorer2(\n  (model_): Sequential(\n    (0): Linear(in_features=41, out_features=30, bias=True)\n    (1): Dropout(p=0.2, inplace=False)\n    (2): BatchNorm1d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): LeakyReLU(negative_slope=0.2)\n    (4): Linear(in_features=30, out_features=19, bias=True)\n    (5): Dropout(p=0.2, inplace=False)\n    (6): BatchNorm1d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): LeakyReLU(negative_slope=0.2)\n    (8): Linear(in_features=19, out_features=24, bias=True)\n    (9): Sigmoid()\n  )\n)"
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:39:14.025285580Z",
     "start_time": "2023-05-04T23:39:13.989686898Z"
    }
   },
   "outputs": [],
   "source": [
    "from colorer.models.gan_colorer import ColorerDiscriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:39:14.490297214Z",
     "start_time": "2023-05-04T23:39:14.443761569Z"
    }
   },
   "outputs": [],
   "source": [
    "disc = ColorerDiscriminator(audio_embedding_dim=9, num_layers=3,colors_count= colors_count).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:39:15.137736962Z",
     "start_time": "2023-05-04T23:39:15.084722300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "ColorerDiscriminator(\n  (adv_layer): Sequential(\n    (0): Linear(in_features=33, out_features=23, bias=True)\n    (1): LeakyReLU(negative_slope=0.2)\n    (2): Dropout(p=0.2, inplace=False)\n    (3): Linear(in_features=23, out_features=13, bias=True)\n    (4): LeakyReLU(negative_slope=0.2)\n    (5): Dropout(p=0.2, inplace=False)\n    (6): Linear(in_features=13, out_features=8, bias=True)\n    (7): Sigmoid()\n  )\n)"
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:39:15.664146844Z",
     "start_time": "2023-05-04T23:39:15.627400651Z"
    }
   },
   "outputs": [],
   "source": [
    "def weighted_mse_loss(input, target, weight=None):\n",
    "    if weight is None:\n",
    "        max_weight = input.size()[1]\n",
    "        weight = torch.tensor([(max_weight - i // 3) // 3 for i in range(max_weight)]).to(input.device)\n",
    "        weight = weight.repeat((len(input), 1))\n",
    "    return (weight * (input - target) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:39:16.279995455Z",
     "start_time": "2023-05-04T23:39:16.243124794Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_noise(n_samples, input_dim, device):\n",
    "    \"\"\"\n",
    "    Function for creating noise vectors: Given the dimensions (n_samples, input_dim)\n",
    "    creates a tensor of that shape filled with random numbers from the normal distribution.\n",
    "    Parameters:\n",
    "        n_samples: the number of samples to generate, a scalar\n",
    "        input_dim: the dimension of the input vector, a scalar\n",
    "        device: the device type\n",
    "    \"\"\"\n",
    "    return torch.randn(n_samples, input_dim, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:32:44.427013164Z",
     "start_time": "2023-05-04T23:32:44.393844662Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "batch_size=64\n",
    "train_dataloader = DataLoader(dataset,drop_last=True, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:32:44.821476969Z",
     "start_time": "2023-05-04T23:32:44.787002459Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_checkpoint_filename(checkpoint_root: str, checkpoint_name: str, epoch: int = None) -> str:\n",
    "    suffix = f\"-{epoch}\" if epoch is not None else \"\"\n",
    "    return f\"{checkpoint_root}/{checkpoint_name}{suffix}.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:32:46.921103606Z",
     "start_time": "2023-05-04T23:32:46.891104251Z"
    }
   },
   "outputs": [],
   "source": [
    "from captioner_train import logger\n",
    "import os\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_root: str, checkpoint_name: str,\n",
    "                    models) -> int:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    filename = get_checkpoint_filename(checkpoint_root, checkpoint_name)\n",
    "\n",
    "    if os.path.isfile(filename):\n",
    "        logger.info(f\"Found {filename}, loading\")\n",
    "        checkpoint = torch.load(filename, map_location=device)\n",
    "        for i, model in enumerate(models):\n",
    "            model.load_state_dict(checkpoint[f\"{i}_state_dict\"])\n",
    "            print('Loaded')\n",
    "        epochs_done = checkpoint[f\"epochs_done\"]\n",
    "        logger.info(f\"{filename} loaded\")\n",
    "        return epochs_done\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:32:47.396796349Z",
     "start_time": "2023-05-04T23:32:47.368905178Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(checkpoint_root: str, checkpoint_name: str, epochs_done: int, backup_epochs: int,\n",
    "                    models):\n",
    "    checkpoint_dict = {}\n",
    "    for i, model in enumerate(models):\n",
    "        checkpoint_dict[f\"{i}_state_dict\"] = model.state_dict()\n",
    "    checkpoint_dict[f\"epochs_done\"] = epochs_done\n",
    "\n",
    "    if not backup_epochs:\n",
    "        # Unconditional save\n",
    "        filename = get_checkpoint_filename(checkpoint_root, checkpoint_name)\n",
    "        torch.save(checkpoint_dict, filename)\n",
    "        logger.info(f\"{filename} saved\")\n",
    "    if backup_epochs and epochs_done and epochs_done % backup_epochs == 0:\n",
    "        # Regular backup\n",
    "        filename = get_checkpoint_filename(checkpoint_root, checkpoint_name, epochs_done)\n",
    "        torch.save(checkpoint_dict, filename)\n",
    "        logger.info(f\"Backup {filename} saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:32:48.723754445Z",
     "start_time": "2023-05-04T23:32:48.675654130Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "ColorerDiscriminator(\n  (adv_layer): Sequential(\n    (0): Linear(in_features=33, out_features=23, bias=True)\n    (1): LeakyReLU(negative_slope=0.2)\n    (2): Dropout(p=0.2, inplace=False)\n    (3): Linear(in_features=23, out_features=13, bias=True)\n    (4): LeakyReLU(negative_slope=0.2)\n    (5): Dropout(p=0.2, inplace=False)\n    (6): Linear(in_features=13, out_features=8, bias=True)\n    (7): Sigmoid()\n  )\n)"
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:46:07.730518497Z",
     "start_time": "2023-05-04T23:41:25.861743619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load checkpoint.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/500 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4ada0276eb5a449bbc4b0bffb5f490e9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train LOSS: colorer 0.6648956465721131, disc 2.283376157283783\n",
      "Train LOSS: colorer 0.6637601470947265, disc 1.3137248158454895\n",
      "Train LOSS: colorer 0.6640550899505615, disc 0.9656254649162292\n",
      "Train LOSS: colorer 0.6654345345497131, disc 0.8260502815246582\n",
      "Train LOSS: colorer 0.6684796595573426, disc 0.7652020156383514\n",
      "Train LOSS: colorer 0.6711865568161011, disc 0.7243647277355194\n",
      "Train LOSS: colorer 0.6739402818679809, disc 0.6477911919355392\n",
      "Train LOSS: colorer 0.6772656440734863, disc 0.5552249997854233\n",
      "Train LOSS: colorer 0.6813999128341675, disc 0.5293837040662766\n",
      "Train LOSS: colorer 0.6852599906921387, disc 0.46845996379852295\n",
      "Train LOSS: colorer 0.6905423498153687, disc 0.43914952874183655\n",
      "Train LOSS: colorer 0.6962795114517212, disc 0.3987971246242523\n",
      "Train LOSS: colorer 0.7012961149215698, disc 0.3751058280467987\n",
      "Train LOSS: colorer 0.7071010518074036, disc 0.3504163548350334\n",
      "Train LOSS: colorer 0.7134268712997437, disc 0.3351072445511818\n",
      "Train LOSS: colorer 0.7203951263427735, disc 0.30825162678956985\n",
      "Train LOSS: colorer 0.7274090218544006, disc 0.29473302513360977\n",
      "Train LOSS: colorer 0.7346702599525452, disc 0.2785845994949341\n",
      "Train LOSS: colorer 0.7427781844139099, disc 0.2731114327907562\n",
      "Train LOSS: colorer 0.751295473575592, disc 0.26928050071001053\n",
      "Train LOSS: colorer 0.7591739678382874, disc 0.2647475451231003\n",
      "Train LOSS: colorer 0.7680673813819885, disc 0.2622859850525856\n",
      "Train LOSS: colorer 0.7776803231239319, disc 0.254713736474514\n",
      "Train LOSS: colorer 0.7883201003074646, disc 0.24855146557092667\n",
      "Train LOSS: colorer 0.7998755812644959, disc 0.24619470536708832\n",
      "Train LOSS: colorer 0.8102772116661072, disc 0.2358693853020668\n",
      "Train LOSS: colorer 0.8240434980392456, disc 0.22980277985334396\n",
      "Train LOSS: colorer 0.8374333572387695, disc 0.22365755587816238\n",
      "Train LOSS: colorer 0.8519917631149292, disc 0.23214589059352875\n",
      "Train LOSS: colorer 0.8710208940505981, disc 0.2132306694984436\n",
      "Train LOSS: colorer 0.8860545039176941, disc 0.20602905005216599\n",
      "Train LOSS: colorer 0.905781762599945, disc 0.20179491490125656\n",
      "Train LOSS: colorer 0.930420367717743, disc 0.19389476627111435\n",
      "Train LOSS: colorer 0.9524730658531189, disc 0.1911945790052414\n",
      "Train LOSS: colorer 0.9759440183639526, disc 0.18275446817278862\n",
      "Train LOSS: colorer 1.0050361633300782, disc 0.17740996927022934\n",
      "Train LOSS: colorer 1.0337161779403687, disc 0.17141126468777657\n",
      "Train LOSS: colorer 1.0676445722579957, disc 0.16277268156409264\n",
      "Train LOSS: colorer 1.099801263809204, disc 0.16058098897337914\n",
      "Train LOSS: colorer 1.1382431411743164, disc 0.1503729112446308\n",
      "Train LOSS: colorer 1.1782179260253907, disc 0.14716894924640656\n",
      "Train LOSS: colorer 1.2244593906402588, disc 0.14142503216862679\n",
      "Train LOSS: colorer 1.2730539274215698, disc 0.13355382531881332\n",
      "Train LOSS: colorer 1.3287966012954713, disc 0.12485383823513985\n",
      "Train LOSS: colorer 1.3840062713623047, disc 0.12162414193153381\n",
      "Train LOSS: colorer 1.432113642692566, disc 0.11617030948400497\n",
      "Train LOSS: colorer 1.49076575756073, disc 0.10788547247648239\n",
      "Train LOSS: colorer 1.5522226858139039, disc 0.09521599858999252\n",
      "Train LOSS: colorer 1.623937611579895, disc 0.10242556594312191\n",
      "Train LOSS: colorer 1.67346200466156, disc 0.08738409169018269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Backup /home/dmitriy/OVE/covergan/weights/smile_colorer_8_colors_sorted-500.pt saved\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import logging\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "n_epochs = 500 # training_params[\"n_epochs\"]\n",
    "lr1 = 1e-3\n",
    "lr2 = 2e-4\n",
    "checkpoint_root ='/home/dmitriy/OVE/covergan/weights'\n",
    "backup_epochs = 100\n",
    "gen_opt = torch.optim.Adam(colorer.parameters(), lr=lr1)\n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=lr2)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "# model_name = f'colorer_{colorer.color_type}_{colorer.colors_count}_colors'\n",
    "model_name = f'smile_colorer_{colorer.colors_count}_colors_{train_dataloader.dataset.sorted_color}'\n",
    "print(\"Trying to load checkpoint.\")\n",
    "epochs_done = load_checkpoint(checkpoint_root, model_name, [colorer, gen_opt])\n",
    "\n",
    "if epochs_done:\n",
    "    logger.info(f\"Loaded a checkpoint with {epochs_done} epochs done\")\n",
    "disc_repeats = 10\n",
    "step = 0\n",
    "log_interval = 10\n",
    "mean_iteration_disc_loss= 0\n",
    "cur_step = 0\n",
    "\n",
    "for epoch in tqdm(range(epochs_done + 1, n_epochs + epochs_done + 1)):\n",
    "    colorer.train()\n",
    "    running_D_test_loss = 0.0\n",
    "    running_G_test_loss = 0.0\n",
    "    count = 0\n",
    "    count_disc = 0\n",
    "    for emotion, palette in train_dataloader:\n",
    "        palette = palette.to(device)\n",
    "\n",
    "        cur_batch_size = len(emotion)\n",
    "        emotion = emotion.float().to(device)\n",
    "        z = get_noise(cur_batch_size, z_dim, device=device)\n",
    "        fake_labels = torch.nn.functional.one_hot(torch.randint(0, 9, (cur_batch_size,)), 9)\n",
    "        # true_labels = torch.ones(batch_size).to(device).unsqueeze(-1)\n",
    "        if count%disc_repeats==0:\n",
    "            fake_covers = colorer(z, fake_labels)\n",
    "            disc_opt.zero_grad()\n",
    "            disc_real_pred = disc(palette, emotion)\n",
    "            real_disc_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred).to(device))\n",
    "            fake_disc_pred = disc(fake_covers.detach(), fake_labels)\n",
    "            gen_disc_loss = criterion(fake_disc_pred, torch.zeros_like(fake_disc_pred).to(device))\n",
    "            disc_loss = (real_disc_loss + gen_disc_loss) / 2\n",
    "            disc_loss.backward()\n",
    "            disc_opt.step()\n",
    "            mean_iteration_disc_loss = disc_loss.item()\n",
    "            running_D_test_loss += mean_iteration_disc_loss\n",
    "            count_disc+=1\n",
    "\n",
    "        disc_opt.zero_grad()\n",
    "        fake_covers =  colorer(z, fake_labels)\n",
    "        fake_disc_pred_gen = disc(fake_covers, fake_labels)\n",
    "        gen_loss = criterion(fake_disc_pred_gen, torch.ones_like(disc_real_pred).to(device))\n",
    "        gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "        running_G_test_loss += gen_loss.item()\n",
    "\n",
    "        count+=1\n",
    "        cur_step+=1\n",
    "\n",
    "    save_checkpoint(checkpoint_root, model_name, epoch, backup_epochs, [colorer, disc, gen_opt, disc_opt])\n",
    "    if (epoch + 1) % log_interval == 0:\n",
    "        avg_G_test_loss = running_G_test_loss / (count + 1)\n",
    "        avg_D_test_loss = running_D_test_loss / (count_disc+ 1)\n",
    "        print('Train LOSS: colorer {}, disc {}'.format(avg_G_test_loss, avg_D_test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T23:19:34.547077012Z",
     "start_time": "2023-05-04T23:19:34.495493636Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T23:19:34.737297248Z",
     "start_time": "2023-05-04T23:19:34.715501293Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:19:40.798654106Z",
     "start_time": "2023-05-04T23:19:40.775795531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colorer.load_state_dict(torch.load('/home/dmitriy/OVE/covergan/weights/smile_colorer_8_colors_sorted-2000.pt')['0_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:46:10.388707979Z",
     "start_time": "2023-05-04T23:46:10.380041696Z"
    }
   },
   "outputs": [],
   "source": [
    "from outer.models.discriminator import Discriminator\n",
    "from outer.models.my_gen_fixed_6figs32_good import MyGeneratorFixedSixFigs32Good\n",
    "\n",
    "generator_type = MyGeneratorFixedSixFigs32Good\n",
    "discriminator_type = Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:46:10.568603752Z",
     "start_time": "2023-05-04T23:46:10.561458958Z"
    }
   },
   "outputs": [],
   "source": [
    "num_gen_layers = 4\n",
    "num_disc_conv_layers = 3\n",
    "num_disc_linear_layers = 2\n",
    "z_dim = 32 # Dimension of the noise vector\n",
    "# z_dim = 512  # Dimension of the noise vector\n",
    "\n",
    "# Painter properties\n",
    "path_count = 3\n",
    "path_segment_count = 4\n",
    "max_stroke_width = 0.01  # relative to the canvas size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:46:10.780656440Z",
     "start_time": "2023-05-04T23:46:10.734073647Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "MyGeneratorFixedSixFigs32Good(\n  (emb): Embedding(9, 9)\n  (model_): Sequential(\n    (0): Linear(in_features=41, out_features=256, bias=True)\n    (1): LeakyReLU(negative_slope=0.2)\n    (2): Linear(in_features=256, out_features=512, bias=True)\n    (3): LeakyReLU(negative_slope=0.2)\n    (4): Linear(in_features=512, out_features=1024, bias=True)\n    (5): LeakyReLU(negative_slope=0.2)\n    (6): Linear(in_features=1024, out_features=805, bias=True)\n    (7): Tanh()\n  )\n)"
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = MyGeneratorFixedSixFigs32Good(z_dim,9,num_gen_layers,128,max_stroke_width)\n",
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:46:10.926925454Z",
     "start_time": "2023-05-04T23:46:10.918689230Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Discriminator(\n  (emb): Embedding(9, 9)\n  (model): Sequential(\n    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (1): LeakyReLU(negative_slope=0.2)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): AdaptiveAvgPool2d(output_size=1)\n    (6): Flatten(start_dim=1, end_dim=-1)\n    (7): Linear(in_features=64, out_features=32, bias=True)\n    (8): Sigmoid()\n  )\n  (adv_layer): Sequential(\n    (0): Linear(in_features=41, out_features=1, bias=True)\n    (1): Sigmoid()\n  )\n)"
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc = Discriminator(128,9,3,2)\n",
    "disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:46:11.115753928Z",
     "start_time": "2023-05-04T23:46:11.107952397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0., 0., 1., 0., 0., 0., 0., 1., 1.])"
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "dataset_image[6][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:46:11.292008412Z",
     "start_time": "2023-05-04T23:46:11.286397872Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_losses(epoch: int, cur_step: int, display_steps: int, bin_steps: int, losses: [(str, [float])]):\n",
    "    if cur_step % display_steps == 0 and cur_step > 0:\n",
    "        loss_stats = []\n",
    "\n",
    "        for loss_name, loss_values in losses:\n",
    "            loss_mean = sum(loss_values[-display_steps:]) / display_steps\n",
    "            if \"loss\" not in loss_name.lower() and \"metric\" not in loss_name.lower():\n",
    "                loss_name += \" Loss\"\n",
    "            loss_stats.append(f\"{loss_name}: {loss_mean}\")\n",
    "\n",
    "            num_examples = (len(loss_values) // bin_steps) * bin_steps\n",
    "            plt.plot(\n",
    "                range(num_examples // bin_steps),\n",
    "                torch.Tensor(loss_values[:num_examples]).view(-1, bin_steps).mean(1),\n",
    "                label=loss_name\n",
    "            )\n",
    "\n",
    "        logger.info(f\"Epoch {epoch} (step {cur_step}): \" + \", \".join(loss_stats))\n",
    "        plt.legend()\n",
    "        print(\"Saving losses to png file\")\n",
    "        import covergan_train\n",
    "        # plt.savefig(f\"{covergan_train.logger.plots_dir}/losses-{epoch}-{cur_step}.png\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    elif cur_step == 0:\n",
    "        logger.info(\"The training is working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:46:11.473578059Z",
     "start_time": "2023-05-04T23:46:11.466595996Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:46:11.699654620Z",
     "start_time": "2023-05-04T23:46:11.639896697Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_gradient_penalty(disc, real, fake, audio_embedding):\n",
    "    # Mix the images together\n",
    "    epsilon = torch.rand((real.size(0), 1, 1, 1), device=real.device)\n",
    "    mixed_images = (real * epsilon + fake * (1 - epsilon)).requires_grad_(True)\n",
    "\n",
    "    # Calculate the critic's scores on the mixed images\n",
    "    mixed_scores = disc(mixed_images, audio_embedding)\n",
    "\n",
    "    # Take the gradient of the scores with respect to the images\n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=mixed_images,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    gradient = gradient.view(len(gradient), -1)\n",
    "\n",
    "    # Calculate the magnitude of every row\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "\n",
    "    # Penalize the mean squared distance of the gradient norms from 1\n",
    "    penalty = ((gradient_norm - 1) ** 2).mean()\n",
    "    return penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:46:11.900620409Z",
     "start_time": "2023-05-04T23:46:11.823469608Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_grad_flow(named_parameters, model_name: str, epoch=None, cur_step=None):\n",
    "    \"\"\"Plots the gradients flowing through different layers in the network during training.\n",
    "    Can be used for checking for possible gradient vanishing/exploding problems.\n",
    "\n",
    "    Usage: Plug this function in Trainer class after loss.backwards() as\n",
    "    `plot_grad_flow(self.model.named_parameters())` to visualize the gradient flow\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the stats\n",
    "    avg_grads = []\n",
    "    max_grads = []\n",
    "    layers = []\n",
    "    for n, p in named_parameters:\n",
    "        if p.requires_grad and (\"bias\" not in n) and p.grad is not None:\n",
    "            layers.append(n)\n",
    "            avg_grads.append(p.grad.abs().mean())\n",
    "            max_grads.append(p.grad.abs().max())\n",
    "\n",
    "    # Initialize plot canvas\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(6, 6)\n",
    "\n",
    "    # Plot\n",
    "    plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.2, lw=1, color=\"c\")  # Max gradients\n",
    "    plt.bar(np.arange(len(max_grads)), avg_grads, alpha=0.2, lw=1, color=\"b\")  # Mean gradients\n",
    "    plt.hlines(0, 0, len(avg_grads) + 1, lw=2, color=\"k\")  # Zero gradient line\n",
    "    plt.xticks(range(0, len(avg_grads), 1), layers, rotation=\"vertical\")\n",
    "\n",
    "    # Set display options\n",
    "    plt.xlim(left=0, right=len(avg_grads))\n",
    "    plt.ylim(bottom=-0.001, top=0.02)  # Zoom in on the lower gradient regions\n",
    "    plt.xlabel('Layers')\n",
    "    plt.ylabel('average gradient')\n",
    "    plt.title(f'Gradient flow in {model_name}')\n",
    "    plt.grid(True)\n",
    "    plt.legend(\n",
    "        [\n",
    "            Line2D([0], [0], color=\"c\", lw=4),\n",
    "            Line2D([0], [0], color=\"b\", lw=4),\n",
    "            Line2D([0], [0], color=\"k\", lw=4)\n",
    "        ],\n",
    "        [\n",
    "            'max-gradient',\n",
    "            'mean-gradient',\n",
    "            'zero-gradient'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.plot()\n",
    "    if epoch is not None:\n",
    "        print(\"Saving grad flow to png file\")\n",
    "        import covergan_train\n",
    "        # plt.savefig(f\"{covergan_train.logger.plots_dir}/grad-flow-{epoch}-{cur_step}.png\")\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:46:12.087885207Z",
     "start_time": "2023-05-04T23:46:12.024605729Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_real_fake_covers(emotions,real_cover_tensor: torch.Tensor, fake_cover_tensor: torch.Tensor,\n",
    "                          disc_real_pred: torch.Tensor = None, disc_fake_pred: torch.Tensor = None,\n",
    "                          epoch=None, cur_step=None, plot_saving_dir=\"./plots\"):\n",
    "    sample_count = 5  # max covers to draw\n",
    "\n",
    "    real_cover_tensor = real_cover_tensor[:sample_count]\n",
    "    fake_cover_tensor = fake_cover_tensor[:sample_count]\n",
    "    emotions = emotions[:sample_count].numpy()\n",
    "\n",
    "    rows = min(sample_count, len(real_cover_tensor))\n",
    "    cols = 2\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(6 * cols, 6 * rows)\n",
    "    for i in range(rows):\n",
    "        real = real_cover_tensor[i]\n",
    "        fake = fake_cover_tensor[i]\n",
    "        emotion = emotions[i]\n",
    "        emo = []\n",
    "        for j in range(len(emotion)):\n",
    "            if emotion[j]==1:\n",
    "                emo.append(key_val[j])\n",
    "        # real_pil = to_pil_image(real,mode=\"RGB\")\n",
    "        fake_pil = to_pil_image(fake,mode=\"RGB\")\n",
    "\n",
    "        real_score = disc_real_pred[i].item() if disc_real_pred is not None else None\n",
    "        fake_score = disc_fake_pred[i].item() if disc_fake_pred is not None else None\n",
    "\n",
    "        for (j, (pil, score)) in enumerate([((real/255).permute(1,2,0), real_score), (fake_pil, fake_score)]):\n",
    "            plt.subplot(rows, cols, i * cols + j + 1)\n",
    "            plt.imshow(pil)\n",
    "            if score is not None:\n",
    "                plt.text(10, 10, f'{emo}', backgroundcolor='w', fontsize=10.0)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.plot()\n",
    "    if epoch is not None:\n",
    "        print(\"Saving covers to png file\")\n",
    "        import covergan_train\n",
    "        # print(covergan_train.logger.plots_dir)\n",
    "        # plt.savefig(f\"{covergan_train.logger.plots_dir}/covers-{epoch}-{cur_step}.png\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:46:12.236523266Z",
     "start_time": "2023-05-04T23:46:12.227041280Z"
    }
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset_image,drop_last=True, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T23:46:12.377121935Z",
     "start_time": "2023-05-04T23:46:12.373694255Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def mismatching_permute(t: torch.Tensor) -> torch.Tensor:\n",
    "    shift = random.randrange(start=0, stop=len(t))\n",
    "    return torch.cat((t[shift:], t[:shift]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "palette_generator = colorer\n",
    "def generate(z, audio_embedding_disc):\n",
    "    if palette_generator is None:\n",
    "        return gen(z, audio_embedding_disc)\n",
    "    return gen(z, audio_embedding_disc, palette_generator=palette_generator)\n",
    "\n",
    "logger.info(f'PyDiffVG uses GPU: {pydiffvg.get_use_gpu()}')\n",
    "# logger.info(gen)\n",
    "# logger.info(disc)\n",
    "\n",
    "n_epochs = 1000\n",
    "disc_repeats = 5#Discriminator runs per iteration\n",
    "\n",
    "\n",
    "disc_lr = gen_lr = 0.0003\n",
    "\n",
    "z_dim = 32\n",
    "disc_slices = 1\n",
    "checkpoint_root = '/home/dmitriy/OVE/covergan/weights'\n",
    "display_steps = 5\n",
    "backup_epochs = 5\n",
    "bin_steps = 20\n",
    "plot_grad = False\n",
    "c_lambda = 10\n",
    "new_loss = torch.nn.BCELoss()\n",
    "new_loss_log = torch.nn.BCEWithLogitsLoss()\n",
    "batch_size=8\n",
    "dataloader = DataLoader(dataset_image,drop_last=True, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=gen_lr)\n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=disc_lr)\n",
    "cgan_out_name='cgan_out'\n",
    "print(\"Trying to load checkpoint.\")\n",
    "epochs_done = load_checkpoint(checkpoint_root, cgan_out_name, [gen, disc, gen_opt, disc_opt])\n",
    "if epochs_done:\n",
    "    logger.info(f\"Loaded a checkpoint with {epochs_done} epochs done\")\n",
    "\n",
    "cur_step = 0\n",
    "generator_losses = []\n",
    "discriminator_losses = []\n",
    "shuffle_losses = []\n",
    "val_metrics = []\n",
    "\n",
    "disc_repeat_cnt = 0\n",
    "mean_iteration_disc_loss, mean_shuffle_disc_loss = 0, 0\n",
    "for epoch in range(epochs_done + 1, n_epochs + epochs_done + 1):\n",
    "    for emotion, image in tqdm(dataloader):\n",
    "        torch.cuda.empty_cache()\n",
    "        emotion = emotion.float().to(device)\n",
    "        image = image.to(device)\n",
    "        cur_batch_size = len(emotion)\n",
    "\n",
    "        z = get_noise(cur_batch_size, z_dim, device=device)\n",
    "\n",
    "        fake_labels = torch.nn.functional.one_hot(torch.randint(0, 9, (cur_batch_size,)), 9).to(device)\n",
    "\n",
    "        true_labels = torch.ones(batch_size).to(device).unsqueeze(-1)\n",
    "\n",
    "        if cur_step%disc_repeats==0:\n",
    "          fake_covers = generate(z, fake_labels)\n",
    "          disc_opt.zero_grad()\n",
    "          disc_real_pred = disc(image.permute(0, 3, 1, 2), emotion)\n",
    "\n",
    "\n",
    "          real_disc_loss = new_loss(disc_real_pred, true_labels)\n",
    "\n",
    "          fake_disc_pred = disc(fake_covers.detach(), fake_labels)\n",
    "\n",
    "          gen_disc_loss = new_loss(fake_disc_pred, torch.zeros(batch_size).unsqueeze(-1).to(device))\n",
    "\n",
    "          disc_loss = (real_disc_loss + gen_disc_loss) / 2\n",
    "          # disc_loss.backward()\n",
    "          disc_opt.step()\n",
    "          mean_iteration_disc_loss = disc_loss.item()\n",
    "          if cur_step % display_steps == 0:\n",
    "            plot_losses(epoch, cur_step, display_steps, bin_steps, [\n",
    "                (\"Generator\", generator_losses),\n",
    "                (\"Discriminator Adversarial\", discriminator_losses),\n",
    "                (\"Discriminator Mismatches\", shuffle_losses)\n",
    "            ])\n",
    "\n",
    "            plot_real_fake_covers(fake_labels, image.permute(0, 3, 1, 2), fake_covers, disc_real_pred, fake_disc_pred, epoch=epoch,\n",
    "                                    cur_step=cur_step)\n",
    "            save_checkpoint(checkpoint_root, cgan_out_name, epoch, 0, [gen, disc, gen_opt, disc_opt])\n",
    "\n",
    "        discriminator_losses.append(mean_iteration_disc_loss)\n",
    "\n",
    "        gen_opt.zero_grad()\n",
    "        fake_covers = generate(z, fake_labels)\n",
    "\n",
    "        fake_disc_pred_gen = disc(fake_covers, fake_labels)\n",
    "        gen_loss = new_loss(fake_disc_pred_gen, true_labels)\n",
    "\n",
    "        # gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "\n",
    "        generator_losses.append(gen_loss.item())\n",
    "\n",
    "        # if cur_step % display_steps == 0:\n",
    "        #     plot_losses(epoch, cur_step, display_steps, bin_steps, [\n",
    "        #         (\"Generator\", generator_losses),\n",
    "        #         (\"Discriminator Adversarial\", discriminator_losses),\n",
    "        #         (\"Discriminator Mismatches\", shuffle_losses)\n",
    "        #     ])\n",
    "\n",
    "        #     plot_real_fake_covers(fake_labels, image.permute(0, 3, 1, 2), fake_covers, disc_real_pred, fake_disc_pred, epoch=epoch,\n",
    "        #                             cur_step=cur_step)\n",
    "        #     save_checkpoint(checkpoint_root, cgan_out_name, epoch, 0, [gen, disc, gen_opt, disc_opt])\n",
    "        \n",
    "        cur_step += 1\n",
    "\n",
    "\n",
    "        # ### Update discriminator with fakes ###\n",
    "        # Zero out the discriminator gradients\n",
    "\n",
    "        # if disc_repeat_cnt == disc_repeats:\n",
    "\n",
    "        # Make sure that enough predictions were made\n",
    "        # Shapes must match\n",
    "\n",
    "        # gp = get_gradient_penalty(disc, image.permute(0,3,1,2).data, fake_cover_tensor.data,\n",
    "        #                           emotion)\n",
    "\n",
    "                    # + c_lambda*gp\n",
    "        # disc_loss = disc_fake_pred.mean() - disc_real_pred.mean() + c_lambda*gp\n",
    "        # Keep track of the average critic loss in this batch\n",
    "        # Update gradients\n",
    "        # disc_loss.backward()\n",
    "        # if plot_grad:\n",
    "        #     plot_grad_flow(disc.named_parameters(), \"discriminator (fakes)\", epoch=epoch, cur_step=cur_step)\n",
    "        # Update optimizer\n",
    "        \n",
    "        \n",
    "        \n",
    "        ###\n",
    "        # shuffle_cover_tensor = mismatching_permute(image.permute(0,3,1,2))###\n",
    "        #\n",
    "        # if True:\n",
    "        #     # ### Update discriminator with matching and shuffled cover-embedding pairs ###\n",
    "        #     disc_opt.zero_grad()\n",
    "        #\n",
    "        #     disc_real_pred = disc(image.permute(0,3,1,2), emotion)\n",
    "        #     disc_shuffle_pred = disc(shuffle_cover_tensor, emotion)\n",
    "        #     # disc_loss = disc_shuffle_pred.mean() - disc_real_pred.mean()\n",
    "        #     disc_loss = new_loss(disc_shuffle_pred,torch.zeros_like(disc_shuffle_pred))+new_loss(disc_real_pred,torch.ones_like(disc_real_pred))\n",
    "        #     mean_shuffle_disc_loss += disc_loss.item() / disc_repeats\n",
    "        #\n",
    "        #     # Update gradients\n",
    "        #     # disc_loss.backward()\n",
    "        #     if plot_grad:\n",
    "        #         plot_grad_flow(disc.named_parameters(), \"discriminator (shuffled pairs)\", epoch=epoch,\n",
    "        #                        cur_step=cur_step)\n",
    "        #     disc_opt.step()\n",
    "\n",
    "            # Keep track of the average discriminator loss\n",
    "        # discriminator_losses.append(mean_iteration_disc_loss)\n",
    "        # shuffle_losses.append(mean_shuffle_disc_loss)\n",
    "        # disc_repeat_cnt += 1\n",
    "        # mean_iteration_disc_loss, mean_shuffle_disc_loss = 0, 0\n",
    "\n",
    "        # ### Update generator ###\n",
    "        # Zero out the generator gradients\n",
    "        # gen_opt.zero_grad()\n",
    "\n",
    "        # # Getting fake shapes, same as in the loop above\n",
    "        # fake_cover_tensor, disc_fake_pred, fig_params = get_fake_pred(should_detach=False)\n",
    "\n",
    "        # p_dist = torch.nn.PairwiseDistance()\n",
    "        # dist_loss_sum = torch.tensor(0.0).to(fake_cover_tensor.device)\n",
    "        # for figs in fig_params:\n",
    "        #     cur_batch_dist_loss = torch.tensor(0.0).to(fake_cover_tensor.device)\n",
    "        #     for ind_x, x in enumerate(figs):\n",
    "        #         for ind_y in range(ind_x + 1, len(figs)):\n",
    "        #             a = x[\"center_point\"]\n",
    "        #             b = figs[ind_y][\"center_point\"]\n",
    "        #             cur_batch_dist_loss += 50000 / (p_dist(a, b)) ** 3\n",
    "        #     dist_loss_sum += cur_batch_dist_loss / len(figs)\n",
    "        #\n",
    "        # dist_loss_sum = dist_loss_sum / len(fig_params)\n",
    "        # dist_loss_sum.backward()\n",
    "        # gen_loss = -disc_fake_pred.mean() + dist_loss_sum\n",
    "        # gen_loss = -disc_fake_pred.mean()\n",
    "\n",
    "        # gen_loss = new_loss(disc_fake_pred,torch.ones_like(disc_fake_pred))\n",
    "        # # gen_loss.backward()\n",
    "        # # gen_loss.backward()\n",
    "        # if plot_grad:\n",
    "        #     plot_grad_flow(gen.named_parameters(), \"generator\", epoch=epoch, cur_step=cur_step)\n",
    "\n",
    "        # Update the weights\n",
    "        # gen_opt.step()\n",
    "\n",
    "        # # Keep track of the generator losses\n",
    "        # generator_losses.append(gen_loss.item())\n",
    "        # # clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-04T23:38:43.859537583Z"
    }
   },
   "outputs": [],
   "source": [
    "z = get_noise(2, z_dim, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader2 = DataLoader(dataset_image,drop_last=True, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(dataloader2))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = gen(z, a, palette_generator=palette_generator,return_diffvg_svg_params=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, params in enumerate(b):\n",
    "    pydiffvg.save_svg(f'/home/dmitriy/OVE/plots/back_diffvg_svg_{ind}.svg', *params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from service_utils import add_filter\n",
    "# from service_utils import OverlayFilter\n",
    "# num_samples = 2\n",
    "# # filtered_samples = round(num_samples // 2)\n",
    "# filtered_samples = num_samples\n",
    "# filters = list(OverlayFilter)\n",
    "# for psvg_cover in b[-filtered_samples:]:\n",
    "#     overlay_filter = random.choice(filters)\n",
    "#     add_filter(psvg_cover, overlay_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
